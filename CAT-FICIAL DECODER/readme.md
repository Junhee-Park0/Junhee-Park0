## CAT-FICIAL DECODER ฅ^•ﻌ•^ฅ

#### 👥 기간 및 인원
기간 : 2025.02.01 ~ 2025.02.27 (1개월)

인원 : 4

#### 🎞 주요 내용

반려동물의 영상을 입력으로 받으면 **프레임화**한 후,

영상 속의 행동을 출력해주는 **멀티모달** 모델 디자인

#### 🪪 역할

CLIP 기반 행동 분석 **파이프라인 구축**

VisionGPT (ViT + GPT) 모델 **아키텍처 개조**

#### 💻 주요 업무 
**[ CLIP 활용 파이프라인 ]**

- 입력 : 반려동물의 영상
- step 1 : 영상 **프레임화**
- step 2 : 프레임별 CLIP 결과 벡터 출력
- step 3 : 프레임별 결과 벡터 **mean pooling**
- step 4 : 결과 벡터에 따라 캡션 출력

**[ VisionGPT 모델 아키텍처 개조 ]**
- 기존 Vision GPT
  - 입력 : 이미지 한 장
  - step 1 : ViT를 이용해 이미지 임베딩
  - step 2 : Cross Attention 층 - ViT와 GPT의 임베딩 공간 일치
  - step 3 : GPT를 이용해 캡션 출력
  
- 수정 사항
  - step 1 전에 **비디오 프레임화** 단계 추가
  - ViT 임베딩 후 **mean-pooling** 단계 추가
  - 기존 코드를 최대한 활용할 수 있도록 **차원 조정**

- Fine Tuning
  - 고양이에 특화된 모델을 위해 **고양이 특성 프레임 데이터** 추가 학습
  - 대용량 데이터를 다루기 위해 경로 대신 **각 이미지 벡터를 pickle**로 저장해 사용
  - 자원의 한계로 마지막 4개 프레임만 학습 진행 

#### ❕인사이트

기존 코드 개조의 가능성 및 방법

멀티모달 구조의 이해 및 경험

각 단계 자동화의 효율성 

모델 성능 향상을 위해 필요한 데이터 양 체감 
오버피팅의 위험성 체감 

#### 💡 활용 기술
 `Python`   `DL`  `CV`   `NLP`  `Multi-Modal` 

#### 🏆 성과

Training Loss 0.07 달성
맥락 반영한 캡션 생성 성공 
